{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports\n",
    "\n",
    "*notes:*\n",
    "- change this to be a normal python file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.11\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import asyncio\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import strym\n",
    "print(strym.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions from analyse_and_create_db.ipynb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "async def async_command_shell(command, verbose: bool = False):\n",
    "    \"\"\"Run command in subprocess (shell).\n",
    "    source: https://fredrikaverpil.github.io/2017/06/20/async-and-await-with-subprocesses/\n",
    "    \"\"\"\n",
    "    # Create subprocess\n",
    "    process = await asyncio.create_subprocess_shell(command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)\n",
    "    # Status\n",
    "    if verbose:\n",
    "        print(\"Started:\", command, \"(pid = \" + str(process.pid) + \")\", flush=True)\n",
    "    # Wait for the subprocess to finish\n",
    "    stdout, stderr = await process.communicate()\n",
    "    # Output\n",
    "    if process.returncode == 0:\n",
    "        if verbose:\n",
    "            print(\"Done:\", command, \"(pid = \" + str(process.pid) + \")\", flush=True)\n",
    "        return stdout.decode().strip()\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"Failed:\", command, \"(pid = \" + str(process.pid) + \")\", flush=True)\n",
    "        raise Exception(stderr.decode().strip())\n",
    "\n",
    "\n",
    "async def iget(file_adress, destination, verbose: bool = False):\n",
    "    '''\n",
    "    wrapper for iRODS iget command\n",
    "    async command using asyncio library\n",
    "    :param file_adress: address on CyVerse fileshare\n",
    "    :param destination: address to download to on the local computer\n",
    "    :return: local address of the file\n",
    "    '''\n",
    "    try:\n",
    "        print(f'Beginning the download of {file_adress}')\n",
    "        await async_command_shell(f'iget -T {file_adress} {destination}', verbose=verbose)\n",
    "        local_address = destination + '/' + file_adress.split('/')[-1]\n",
    "        print(f'Download was successful')\n",
    "        return local_address\n",
    "    except Exception as e:\n",
    "        raise Exception(f'Error while downloading file at:'\n",
    "                        f'\\n\\tremote: {file_adress}'\n",
    "                        f'\\n\\tto local address: {destination}`'\n",
    "                        f'\\n\\tFailing on {e}')\n",
    "\n",
    "\n",
    "def init_cache(local_folder):\n",
    "    '''\n",
    "    clears the cache if exists and initialise it\n",
    "    :param local_folder: root folder for the analysis\n",
    "    :return: temporary cache address\n",
    "    '''\n",
    "    subprocess.run(['cd', local_folder],\n",
    "                   stdout=subprocess.PIPE,\n",
    "                   stderr=subprocess.PIPE,\n",
    "                   universal_newlines=True)\n",
    "    local_folder_absolute = subprocess.run(['pwd'],\n",
    "                   stdout=subprocess.PIPE,\n",
    "                   stderr=subprocess.PIPE,\n",
    "                   universal_newlines=True).stdout.strip()\n",
    "    files = subprocess.run(['ls'],\n",
    "                   stdout=subprocess.PIPE,\n",
    "                   stderr=subprocess.PIPE,\n",
    "                   universal_newlines=True)\n",
    "    files = files.stdout.split(sep='\\n')\n",
    "    if 'temp_cache' in files:\n",
    "        subprocess.run(['rm', '-r', '-f', 'temp_cache'],\n",
    "                   stdout=subprocess.PIPE,\n",
    "                   stderr=subprocess.PIPE,\n",
    "                   universal_newlines=True)\n",
    "    subprocess.run(['mkdir', 'temp_cache'],\n",
    "               stdout=subprocess.PIPE,\n",
    "               stderr=subprocess.PIPE,\n",
    "               universal_newlines=True)\n",
    "    temp_cache_address = f'{local_folder_absolute}/temp_cache'\n",
    "    print('Cache cleared')\n",
    "    return temp_cache_address\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cutting CSV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def find_ts_time_close(ts_time, event_time):\n",
    "    \"\"\"\n",
    "    Finds the available time point of a time series closest to a given point in time\n",
    "    :param ts_time: Time Series time list\n",
    "    :param event_time: Time at which we want the value\n",
    "    :return: the time point available for the time series\n",
    "    \"\"\"\n",
    "    min_index = np.argmin([np.abs(time - event_time) for time in ts_time])\n",
    "    return ts_time[min_index]\n",
    "\n",
    "def perform_cut(local_address, previous_cut_time, next_cut_time, event_time):\n",
    "    \"\"\"\n",
    "    cuts a CAN/GPS time series before and after the event\n",
    "    :param local_address: local address of the file to cut\n",
    "    :param previous_cut_time: float, seconds before the event to keep\n",
    "    :param next_cut_time: float, seconds after the event to keep\n",
    "    :param event_time: float\n",
    "    :return: Path of the cutted file\n",
    "    \"\"\"\n",
    "    df_can = pd.read_csv(local_address)\n",
    "    filename = local_address.split('/')[-1]\n",
    "    folders = local_address.split('/')[:-1]\n",
    "    foldername = ''\n",
    "    for folder in folders:\n",
    "        foldername += folder\n",
    "    new_filename = 'cutted__' + filename\n",
    "\n",
    "    time_beginning_cut = find_ts_time_close(df_can['Time'], event_time - previous_cut_time)\n",
    "    time_ending_cut = find_ts_time_close(df_can['Time'], event_time + next_cut_time)\n",
    "    cutted_df = df_can.loc[(df_can['Time'] >= time_beginning_cut) & (df_can['Time'] <= time_ending_cut)]\n",
    "    cutted_df.to_csv(path_or_buf=f'results/{new_filename}')\n",
    "    new_path = foldername + '/' + new_filename\n",
    "    return new_path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download and serve file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "class FileServer:\n",
    "    \"\"\"\n",
    "    Class handling file download and caching, csv filtering and time cuts to be sent to CAN -> ROS playback\n",
    "    \"\"\"\n",
    "    # attributes\n",
    "    data = None\n",
    "    current_remote_adresses = None\n",
    "    current_event = None\n",
    "    can_local_address = None\n",
    "    gps_local_address = None\n",
    "    index = 0\n",
    "    max_index = None\n",
    "    previous_cut_time = None\n",
    "    next_cut_time = None\n",
    "    local_root_folder = None\n",
    "\n",
    "    # methods\n",
    "    def __init__(self, analysis_path, local_root_folder):\n",
    "        \"\"\"\n",
    "        Reads from a CSV analysis file\n",
    "        :param analysis_path: string of the path of the CSV taken from the analysis\n",
    "        :param local_root_folder: Local root for the download folder\n",
    "        \"\"\"\n",
    "        self.local_root_folder = local_root_folder\n",
    "        self.data = pd.read_csv(analysis_path)\n",
    "        self.max_index = len(self.data)\n",
    "\n",
    "    def filter(self, cc_state: [int] = None, speed: {str: int} = None, vin: [str] = None, date: {str: str} = None, event_type: [str] = None):\n",
    "        \"\"\"\n",
    "        filter the rows based on those criteria\n",
    "        :param cc_state: list of acceptable controller state values\n",
    "        :param speed: {min: int min_speed in km/h, max: int max_speed in km/h}\n",
    "        :param vin: list of acceptable vehicle identification numbers\n",
    "        :param date: {beg: date, end: date}, with date as strings, formatted as YYYY-MM-DD-HH-MM-SS\n",
    "        :param event_type: list of acceptable event types. possible event types are:\n",
    "            - car_crossing\n",
    "            - <more to come in the future>\n",
    "        :return: updates self.data to only keep the desirable instances\n",
    "        \"\"\"\n",
    "        if event_type is not None:\n",
    "            self.data = self.data.loc[self.data['event_type'] in event_type]\n",
    "        if vin is not None:\n",
    "            self.data = self.data.loc[self.data['vin'] in vin]\n",
    "        if cc_state is not None:\n",
    "            self.data = self.data.loc[self.data['event_cc_state'] in cc_state]\n",
    "        if speed is not None:\n",
    "            self.data = self.data.loc[(self.data['event_speeds'] >= speed['min'])\n",
    "                                  & (self.data['event_speeds'] >= speed['min'])]\n",
    "        if date is not None:\n",
    "            self.data = self.data.loc[(self.data['date'] >= date['min'])\n",
    "                                  & (self.data['date'] >= date['min'])]\n",
    "        self.max_index = len(self.data)\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.max_index is None:\n",
    "            return f'FileServer filtering is not finished'\n",
    "        else:\n",
    "            return f'file server with {self.max_index} files ready to be served, current index is: {self.index}'\n",
    "\n",
    "    async def next(self, ignore_gps_file: bool = False):\n",
    "        \"\"\"\n",
    "        clears cache & downloads the next couple of files\n",
    "        :param: ignore_gps_file: set to True to avoid downloading the GPS file\n",
    "        :return: - object with paths to the downloaded CAN and GPS file\n",
    "        {'can': str, 'gps': str, 'remote_addresses': {'can': str, 'gps': str}}\n",
    "                 - if the maximum index is reached, returns an exception as:\n",
    "        Exception('max_index')\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f'serving and preprocessing file, number {self.index} out of {self.max_index}')\n",
    "            if self.index < self.max_index:\n",
    "                cache = init_cache(self.local_root_folder)\n",
    "                self.current_event = self.data.iloc[self.index]\n",
    "                self.current_remote_adresses = ast.literal_eval(self.current_event['remote_addresses'])\n",
    "\n",
    "                self.can_local_address = await iget(self.current_remote_adresses['can'], cache)\n",
    "                if ignore_gps_file:\n",
    "                    self.gps_local_address = None\n",
    "                else:\n",
    "                    self.gps_local_address = await iget(self.current_remote_adresses['gps'], cache)\n",
    "\n",
    "                self.index += 1\n",
    "\n",
    "                local_addresses = self.cut_can_file()\n",
    "                print(f'Download and preprocessing of {local_addresses} was successful')\n",
    "                return local_addresses\n",
    "            else:\n",
    "                raise Exception('max_index')\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f'Downloading next file failed on {e}')\n",
    "\n",
    "    def set_cut(self, previous, next):\n",
    "        \"\"\"\n",
    "        sets the values of the parameters of the cut for the csv CAN/GPS files\n",
    "        :param previous: number of seconds kept before the event\n",
    "        :param next: number of seconds kept after the event\n",
    "        :return: void. updates the attributes of the file server\n",
    "        \"\"\"\n",
    "        self.previous_cut_time = previous\n",
    "        self.next_cut_time = next\n",
    "\n",
    "    def cut_can_file(self):\n",
    "        \"\"\"\n",
    "        cut the current file according to the cutting parameters defined\n",
    "        \"\"\"\n",
    "        event_time = self.current_event['event_time']\n",
    "        can_new_path = perform_cut(self.can_local_address, self.previous_cut_time, self.next_cut_time, event_time)\n",
    "        gps_new_path = None\n",
    "        if self.gps_local_address is not None:\n",
    "            gps_new_path = perform_cut(self.can_local_address, self.previous_cut_time, self.next_cut_time, event_time)\n",
    "        return {\n",
    "            'can': can_new_path,\n",
    "            'gps': gps_new_path,\n",
    "        }\n",
    "\n",
    "    def clear(self):\n",
    "        init_cache(self.local_root_folder)\n",
    "        print('Cache cleared')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# example of file serving (automate this with an inner state of file handler out of a notebook?)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1627907522.075218\n",
      "2021-08-02-13-13-02_2T3W1RFVXKW033343_CAN_Messages.csv\n",
      "UsersnoecarrasDocuments03_Berkeley_EECScoursCapstone_RL_validationcapstone_circles_rl_validationdatabase_explorationtemp_cache\n",
      "1627907492.074878\n",
      "1627907552.075198\n",
      "UsersnoecarrasDocuments03_Berkeley_EECScoursCapstone_RL_validationcapstone_circles_rl_validationdatabase_explorationtemp_cache/cutted__2021-08-02-13-13-02_2T3W1RFVXKW033343_CAN_Messages.csv\n",
      "gps todo as well\n",
      "2021-08-02-13-13-02_2T3W1RFVXKW033343_CAN_Messages.csv\n",
      "UsersnoecarrasDocuments03_Berkeley_EECScoursCapstone_RL_validationcapstone_circles_rl_validationdatabase_explorationtemp_cache\n",
      "1627907492.074878\n",
      "1627907552.075198\n",
      "UsersnoecarrasDocuments03_Berkeley_EECScoursCapstone_RL_validationcapstone_circles_rl_validationdatabase_explorationtemp_cache/cutted__2021-08-02-13-13-02_2T3W1RFVXKW033343_CAN_Messages.csv\n",
      "{'can': 'UsersnoecarrasDocuments03_Berkeley_EECScoursCapstone_RL_validationcapstone_circles_rl_validationdatabase_explorationtemp_cache/cutted__2021-08-02-13-13-02_2T3W1RFVXKW033343_CAN_Messages.csv', 'gps': 'UsersnoecarrasDocuments03_Berkeley_EECScoursCapstone_RL_validationcapstone_circles_rl_validationdatabase_explorationtemp_cache/cutted__2021-08-02-13-13-02_2T3W1RFVXKW033343_CAN_Messages.csv'}\n"
     ]
    }
   ],
   "source": [
    "# initialize the file server\n",
    "small_analysis_path = '/Users/noecarras/Documents/03_Berkeley_EECS/cours/Capstone_RL_validation/capstone_circles_rl_validation/database_exploration/results/analysis&example_small_analysis_car_crossings&create_on=2021-11-29 19:28:05.079333&s=20&p=50&n=40.csv'\n",
    "file_server = FileServer(analysis_path=small_analysis_path)\n",
    "# filtering through events\n",
    "file_server.filter(speed={'min': 90, 'max': 200})\n",
    "# setting cuts times\n",
    "file_server.set_cut(previous=30, next=30)\n",
    "# serving a couple of files\n",
    "newfiles_1 = await file_server.next()\n",
    "print(newfiles_1)\n",
    "newfiles_2 = await file_server.next()\n",
    "print(newfiles_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "todo:\n",
    "- launch the full analysis on CyVerse Jupyter-strym\n",
    "- rework on docker\n",
    "- dockerise all of this\n",
    "- find a good pattern for the file handler in the container for looping\n",
    "- same for the ROS container, do not rebuild it everytime, just pass more data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}