{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Imports\n",
    "\n",
    "*notes:*\n",
    "- everything is sequentially made in this file because strymread can only be launched within jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/hl/z5cl05zs2415mcd5gg57tb240000gn/T/ipykernel_35660/2030520933.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mstrym\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mstrymread\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mstrym\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mstrymmap\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/03_Berkeley_EECS/cours/Capstone_RL_validation/capstone_circles_rl_validation/venv/lib/python3.7/site-packages/strym/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mstrym\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mstrym\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mstrym\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m__version__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mstrym\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m__author__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mstrym\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m__email__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/03_Berkeley_EECS/cours/Capstone_RL_validation/capstone_circles_rl_validation/venv/lib/python3.7/site-packages/strym/strym.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcsv\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mmpl_toolkits\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmplot3d\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mAxes3D\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mmatplotlib\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcm\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/03_Berkeley_EECS/cours/Capstone_RL_validation/capstone_circles_rl_validation/venv/lib/python3.7/site-packages/matplotlib/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[0;31m# cbook must import matplotlib only within function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m \u001B[0;31m# definitions, so it is safe to import from it here.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 107\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_api\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcbook\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdocstring\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrcsetup\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    108\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcbook\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mMatplotlibDeprecationWarning\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msanitize_sequence\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcbook\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmplDeprecation\u001B[0m  \u001B[0;31m# deprecated\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.7/3.7.12_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.7/3.7.12_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.7/3.7.12_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_load_unlocked\u001B[0;34m(spec)\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.7/3.7.12_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap_external.py\u001B[0m in \u001B[0;36mexec_module\u001B[0;34m(self, module)\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.7/3.7.12_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap_external.py\u001B[0m in \u001B[0;36mget_code\u001B[0;34m(self, fullname)\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.7/3.7.12_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap_external.py\u001B[0m in \u001B[0;36mget_data\u001B[0;34m(self, path)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "from strym import strymread\n",
    "from strym import strymmap\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import strym\n",
    "print(strym.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions\n",
    "\n",
    "## iRODS command wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ils():\n",
    "    '''\n",
    "    wrapper for iRODS ils command\n",
    "    :return: list of files and folder in the current folder\n",
    "    '''\n",
    "    process_files = subprocess.run(['ils'],\n",
    "                                   stdout=subprocess.PIPE,\n",
    "                                   stderr=subprocess.PIPE,\n",
    "                                   universal_newlines=True)\n",
    "    files = process_files.stdout.split(sep='\\n')[1:-1]\n",
    "    return [f.strip() for f in files]\n",
    "\n",
    "\n",
    "def icd(destination):\n",
    "    '''\n",
    "    wrapper for iRODS icd command\n",
    "    :param destination: destination to which go to\n",
    "    :return: subprocess output\n",
    "    '''\n",
    "    return subprocess.run(['icd', destination],\n",
    "                          stdout=subprocess.PIPE,\n",
    "                          stderr=subprocess.PIPE,\n",
    "                          universal_newlines=True)\n",
    "\n",
    "\n",
    "def ipwd():\n",
    "    '''\n",
    "    wrapper for iRODS ipwd command\n",
    "    :return: current directory on CyVerse\n",
    "    '''\n",
    "    pwd = subprocess.run(['ipwd'],\n",
    "                          stdout=subprocess.PIPE,\n",
    "                          stderr=subprocess.PIPE,\n",
    "                          universal_newlines=True)\n",
    "    out = pwd.stdout.strip().strip('\\n')\n",
    "    print('pwd output is:', out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "async def async_command_shell(command, verbose: bool = False):\n",
    "    \"\"\"Run command in subprocess (shell).\n",
    "    source: https://fredrikaverpil.github.io/2017/06/20/async-and-await-with-subprocesses/\n",
    "    \"\"\"\n",
    "    # Create subprocess\n",
    "    process = await asyncio.create_subprocess_shell(command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)\n",
    "    # Status\n",
    "    if verbose:\n",
    "        print(\"Started:\", command, \"(pid = \" + str(process.pid) + \")\", flush=True)\n",
    "    # Wait for the subprocess to finish\n",
    "    stdout, stderr = await process.communicate()\n",
    "    # Output\n",
    "    if process.returncode == 0:\n",
    "        if verbose:\n",
    "            print(\"Done:\", command, \"(pid = \" + str(process.pid) + \")\", flush=True)\n",
    "        return stdout.decode().strip()\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"Failed:\", command, \"(pid = \" + str(process.pid) + \")\", flush=True)\n",
    "        raise Exception(stderr.decode().strip())\n",
    "\n",
    "\n",
    "async def iget(file_adress, destination, verbose: bool = False):\n",
    "    '''\n",
    "    wrapper for iRODS iget command\n",
    "    async command using asyncio library\n",
    "    :param file_adress: address on CyVerse fileshare\n",
    "    :param destination: address to download to on the local computer\n",
    "    :return: local address of the file\n",
    "    '''\n",
    "    try:\n",
    "        await async_command_shell(f'iget -T {file_adress} {destination}', verbose=verbose)\n",
    "        local_address = destination + '/' + file_adress.split('/')[-1]\n",
    "        return local_address\n",
    "    except Exception as e:\n",
    "        raise Exception(f'Error while downloading file at:'\n",
    "                        f'\\n\\tremote: {file_adress}'\n",
    "                        f'\\n\\tto local address: {destination}`'\n",
    "                        f'\\n\\tFailing on {e}')\n",
    "\n",
    "\n",
    "def init_cache(local_folder):\n",
    "    '''\n",
    "    clears the cache if exists and initialise it\n",
    "    :param local_folder: root folder for the analysis\n",
    "    :return: temporary cache address\n",
    "    '''\n",
    "    subprocess.run(['cd', local_folder],\n",
    "                   stdout=subprocess.PIPE,\n",
    "                   stderr=subprocess.PIPE,\n",
    "                   universal_newlines=True)\n",
    "    local_folder_absolute = subprocess.run(['pwd'],\n",
    "                   stdout=subprocess.PIPE,\n",
    "                   stderr=subprocess.PIPE,\n",
    "                   universal_newlines=True).stdout.strip()\n",
    "    files = subprocess.run(['ls'],\n",
    "                   stdout=subprocess.PIPE,\n",
    "                   stderr=subprocess.PIPE,\n",
    "                   universal_newlines=True)\n",
    "    files = files.stdout.split(sep='\\n')\n",
    "    if 'temp_cache' in files:\n",
    "        subprocess.run(['rm', '-r', '-f', 'temp_cache'],\n",
    "                   stdout=subprocess.PIPE,\n",
    "                   stderr=subprocess.PIPE,\n",
    "                   universal_newlines=True)\n",
    "    subprocess.run(['mkdir', 'temp_cache'],\n",
    "               stdout=subprocess.PIPE,\n",
    "               stderr=subprocess.PIPE,\n",
    "               universal_newlines=True)\n",
    "    temp_cache_address = f'{local_folder_absolute}/temp_cache'\n",
    "    return temp_cache_address\n",
    "\n",
    "# KEEP IDEA FOR LATER AUTOMATED TESTING:\n",
    "# - handling of the file download\n",
    "# - handling of errors\n",
    "# - accuracy of the output path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fileshare exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def findall_files(root, verbose: bool = False):\n",
    "    '''\n",
    "    finds all files within the root directory and recursively below\n",
    "    :param root: str, root file from which to begin the search\n",
    "    :param verbose: bool, set to True to see fuller logs\n",
    "    :return: List<str>\n",
    "    '''\n",
    "    dir_queue = [root]\n",
    "    files = []\n",
    "\n",
    "    while len(dir_queue) != 0:\n",
    "        current_dir = dir_queue.pop()\n",
    "        icd(current_dir)\n",
    "        queue = ils()\n",
    "        if verbose:\n",
    "            print('---------')\n",
    "            print('current queue dir: ', dir_queue)\n",
    "            print('current directory is: ', current_dir)\n",
    "            print('current file queue is: ', queue)\n",
    "\n",
    "        for f in queue:\n",
    "            if verbose:\n",
    "                print('current file tests on: ', f, ' and test gives f[0:2]: ', f[0:2], ' and f[-4:] is: ', f[-4:])\n",
    "            # avoid dashcams and bafiles folders, only use the libpanda ones -> reduces the number of files to scan for\n",
    "            if f[0:2] == 'C-' and 'bagfiles' not in f and 'dashcams' not in f:\n",
    "                dir_queue.append(f[3:])\n",
    "                if verbose:\n",
    "                    print('appending dir queue; ', f)\n",
    "            elif f[-4:] == '.csv':\n",
    "                # We also conserve the current folder to get the entire path to the file\n",
    "                current_folder = ipwd()\n",
    "                files.append(f'{current_folder}/{f}')\n",
    "                if verbose:\n",
    "                    print('appending file; ', f)\n",
    "\n",
    "        if verbose:\n",
    "            print('found ', len(files), ' files')\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def can_gps_coupling(files):\n",
    "    '''\n",
    "    links the CAN and GPS from same acquisitions\n",
    "    :param files: array of file adresses\n",
    "    :return: List<{'can': str, 'gps': str || None}>\n",
    "    '''\n",
    "    file_list = []\n",
    "    for file in files:\n",
    "        if '_CAN_Messages.csv' in file:\n",
    "            file_list.append({'can': file, 'gps': None})\n",
    "\n",
    "    for i in range(len(file_list)):\n",
    "        file_gps = file_list[i]['can'][0:-17] + '_GPS_Messages.csv'\n",
    "        if file_gps in files:\n",
    "            file_list[i]['gps'] = file_gps\n",
    "\n",
    "    return file_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car crossing detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_metadata(canfile, gpsfile, ignore_gps_file: bool = False, verbose: bool = False):\n",
    "    \"\"\"\n",
    "    :param canfile: string, csv file\n",
    "    :param gpsfile: string, csv file\n",
    "    :param ignore_gps_file: set to True to avoid downloading the GPS file\n",
    "    :return: strymreads of can and gps files, dictionnary of the meta-datas associated\n",
    "    TODO: find how to extract the metadata here (maybe from strymread)?\n",
    "      Find also the desired metadata to be logged into the DB\n",
    "      -> what could be the useful thing to sort on? car model? day? other things?\n",
    "    \"\"\"\n",
    "\n",
    "    # read canfile\n",
    "    s = strymread(csvfile=canfile)\n",
    "    if verbose:\n",
    "        print(f'reading of {canfile} was succesful? {s.success}')\n",
    "\n",
    "    # read and link gpsfile\n",
    "    if not ignore_gps_file:\n",
    "        g = strymmap(csvfile=gpsfile)\n",
    "        if verbose:\n",
    "            print(f'reading of {gpsfile} was succesful? {g.success}')\n",
    "    else:\n",
    "        g = None\n",
    "        if verbose:\n",
    "            print(f'reading of GPS file was ignored')\n",
    "\n",
    "    # metadata from filename\n",
    "    date_time = canfile.split('/')[-1][0:19]\n",
    "    vin = canfile.split('/')[-1][20:37]\n",
    "\n",
    "    return s, g, {'date_time': date_time, 'vin': vin}\n",
    "\n",
    "\n",
    "def read_data(can, gps):\n",
    "    \"\"\"\n",
    "    :param can: strymread object\n",
    "    :param gps: strymmap object\n",
    "    :return: speed, lead_distance, cruise_control time series\n",
    "    \"\"\"\n",
    "    speed_ts = can.speed()\n",
    "    lead_distance_ts = can.lead_distance()\n",
    "    cruise_control_state_ts = can.acc_state()\n",
    "    return speed_ts, lead_distance_ts, cruise_control_state_ts\n",
    "\n",
    "\n",
    "def find_ts_state_at_given_time(ts, ts_time, event_time):\n",
    "    \"\"\"\n",
    "    Finds the value of a time series at a given point in time. Uses the closest time point to the event\n",
    "    :param ts: Time Series messages list to search within\n",
    "    :param ts_time: Time Series time list\n",
    "    :param event_time: Time at which we want the value\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    min_index = np.argmin([np.abs(time - event_time) for time in ts_time])\n",
    "    return ts[min_index]\n",
    "\n",
    "\n",
    "def find_crossing(speed, lead_distance, cruise_control_state, speed_treshold = 20,\n",
    "                  prev_treshold = 10, next_treshold = 5, verbose: bool = False):\n",
    "    \"\"\"\n",
    "    finds the time where car crossing events happens, from ts associated to 1 specific acquisition\n",
    "    this functions find the acceptable intervals where the constraints on speed and cruise control are valid,\n",
    "    then finds the places where crossings happens, filtering them by the acceptable times (this allows to handle\n",
    "    different sapling frequencies over the different time series)\n",
    "\n",
    "    NOTE: choice of the default value:\n",
    "        - about 5 meters for a vehicle size --> immediately dangerous if a vehicle comes closer than this:\n",
    "            go from more than 10 to less than 5\n",
    "        - 20 m/s is approximately highway speeds of 45MPH\n",
    "            treshold speed to see dangerous crossings only at high speeds\n",
    "\n",
    "    :param speed: Time Series of the speed\n",
    "    :param lead_distance: Time Series of the Speed\n",
    "    :param cruise_control_state: Time Series of the Controller state (=6 if activated)\n",
    "    :param speed_treshold: minimum speed to consider a dangerous time crossing event\n",
    "    :param prev_treshold: minimum lead distance before the crossing to consider the event as a car crossing\n",
    "    :param next_treshold: maximum lead distance after the crossing to consider the car crossing as dangerous\n",
    "    :param verbose: Set to true to get more logs\n",
    "\n",
    "    :return: array<time>, of event_times of car crossing events\n",
    "\n",
    "    TODO: refine the cruise control state to also encompass other semi-activated states as if controller on?\n",
    "    \"\"\"\n",
    "    kmh_speed_treshold = speed_treshold * 3.6\n",
    "    event_times = []\n",
    "    controller_states = []\n",
    "    speeds = []\n",
    "    unacceptable_crossings = []\n",
    "\n",
    "    lead_distance_list = lead_distance['Message']\n",
    "    lead_time_list = lead_distance['Time']\n",
    "    len_lead = len(lead_time_list)\n",
    "\n",
    "    speed_list = speed['Message']\n",
    "    speed_time_list = speed['Time']\n",
    "    len_speed = len(speed_time_list)\n",
    "\n",
    "    cc_state_list = cruise_control_state['Message']\n",
    "    cc_state_time_list = cruise_control_state['Time']\n",
    "\n",
    "    # Acceptable times for cruise control state and speed:\n",
    "    # composed of time interval objects {\"beg\": time_begining, \"end\": time_ending}\n",
    "    acceptable_range_speed = []\n",
    "    currently_valid = False\n",
    "    current_interval = {\"beg\": None, \"end\": None}\n",
    "    for i in range(len_speed):\n",
    "        if speed_list[i] >= kmh_speed_treshold and not currently_valid:\n",
    "            currently_valid = True\n",
    "            current_interval['beg'] = speed_time_list[i]\n",
    "        elif speed_list[i] < kmh_speed_treshold and currently_valid:\n",
    "            currently_valid = False\n",
    "            current_interval['end'] = speed_time_list[i]\n",
    "            acceptable_range_speed.append(current_interval)\n",
    "            current_interval = {\"beg\": None, \"end\": None}\n",
    "\n",
    "    # case if the speed is still acceptable at the end of the file:\n",
    "    if current_interval['beg'] and not current_interval['end']:\n",
    "        current_interval['end'] = speed_time_list[-1]\n",
    "        acceptable_range_speed.append(current_interval)\n",
    "\n",
    "    for i in range(1, len_lead):\n",
    "        is_lead_distance_acceptable = (lead_distance_list[i - 1] >= prev_treshold) and (lead_distance_list[i] <= next_treshold)\n",
    "        if is_lead_distance_acceptable:\n",
    "            # if at this time a car crossing occurs, we check that the conditions to store this event are valid\n",
    "            time_event = lead_time_list[i]\n",
    "            unacceptable_crossings.append(time_event)\n",
    "            for interval in acceptable_range_speed:\n",
    "                if interval['beg'] <= time_event <= interval['end']:\n",
    "                    event_times.append(time_event)\n",
    "                    controller_states.append(find_ts_state_at_given_time(cc_state_list, cc_state_time_list, time_event))\n",
    "                    speeds.append(find_ts_state_at_given_time(speed_list, speed_time_list, time_event))\n",
    "\n",
    "    if verbose:\n",
    "        print(f'acceptable range for speed > {speed_treshold} m/s: {acceptable_range_speed}')\n",
    "        print(f'number of crossings detected: {len(unacceptable_crossings)}')\n",
    "        print(f'number of valid crossings detected: {len(event_times)}')\n",
    "        print(f'event times of valid crossings: {event_times}')\n",
    "\n",
    "    return event_times, controller_states, speeds\n",
    "\n",
    "\n",
    "def plot_events_over_lead(name, lead, times, event_times):\n",
    "    \"\"\"\n",
    "    TODO document this\n",
    "    TODO use plotly instead of pyplot\n",
    "    :param lead:\n",
    "    :param times:\n",
    "    :param event_times:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # create a fake list of event times to see them on the graph\n",
    "    def fake(time):\n",
    "        if time in event_times:\n",
    "            return 252\n",
    "        else:\n",
    "            return 0\n",
    "    event_times_fake = [fake(time) for time in times]\n",
    "    # plot the figure\n",
    "    fig, ax = plt.subplots()\n",
    "    l = ax.plot(times, lead, 'b.')\n",
    "    e = ax.plot(times, event_times_fake, 'r-')\n",
    "    plt.title(name)\n",
    "    plt.ion()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File handler & cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class FileHandler:\n",
    "    \"\"\"\n",
    "    Class handling download and delete of files to be analyzed\n",
    "    \"\"\"\n",
    "    # attributes\n",
    "    all_files = None\n",
    "    coupled_files = None\n",
    "\n",
    "    remote_adresses = None\n",
    "    can_local_address = None\n",
    "    gps_local_address = None\n",
    "    # note: first file served after incrementation\n",
    "    index = 0\n",
    "    max_index = None\n",
    "\n",
    "    # methods\n",
    "    def __init__(self):\n",
    "        print('File Handler ready for file exploration')\n",
    "\n",
    "    def explore(self, analyze: bool = True, root: str = '', exploration_name = None,\n",
    "                 previous_exploration_path = None, verbose: bool = False):\n",
    "        \"\"\"\n",
    "        Initialises the path objects, then file handler attributes\n",
    "\n",
    "        :param analyze: True if you want to explore files from CyVerse,\n",
    "        False if you want to use a file giving the coupled files from a previous FileShare exploration\n",
    "        :param root: root of the search for exploring on CyVerse\n",
    "        :param exploration_name: name for the coupled file local copy\n",
    "        :param previous_exploration_path: local address towards the file giving the coupled files from a previous\n",
    "        FileShare exploration\n",
    "\n",
    "        TODO: include a call to an iinit irods function\n",
    "        \"\"\"\n",
    "        # case of file share exploration\n",
    "        if analyze:\n",
    "            try:\n",
    "                self.all_files = findall_files(root, verbose)\n",
    "                self.coupled_files = can_gps_coupling(self.all_files)\n",
    "                self.max_index = len(self.coupled_files)\n",
    "                # save the csv file\n",
    "                output_filename = coupled_files_file_namer(exploration_name, root)\n",
    "                df = pd.DataFrame(data={'Files': self.coupled_files})\n",
    "                df.to_csv(path_or_buf=f'results/{output_filename}')\n",
    "                if verbose:\n",
    "                    print('exploration logged as: ', output_filename)\n",
    "            except Exception as e:\n",
    "                print(f'CyVerse FileShare exploration failed on: {e}')\n",
    "\n",
    "        # case of using a file to get the coupled addresses\n",
    "        else:\n",
    "            try:\n",
    "                df = pd.read_csv(previous_exploration_path)\n",
    "                self.coupled_files = df['Files']\n",
    "            except Exception as e:\n",
    "                print(f'retrieving from file at {previous_exploration_path} failed on: {e}')\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.max_index is None:\n",
    "            return f'FileShare exploration is not finished'\n",
    "        else:\n",
    "            return f'file handler with {self.max_index} couples, current index is: {self.index}'\n",
    "\n",
    "\n",
    "    async def next(self, ignore_gps_file: bool = False):\n",
    "        \"\"\"\n",
    "        clears cache & downloads the next couple of files\n",
    "        :param: ignore_gps_file: set to True to avoid downloading the GPS file\n",
    "        :return: - object with paths to the downloaded CAN and GPS file\n",
    "        {'can': str, 'gps': str, 'remote_addresses': {'can': str, 'gps': str}}\n",
    "                 - if the maximum index is reached, returns an exception as:\n",
    "        Exception('max_index')\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self.index < self.max_index:\n",
    "                cache = init_cache('database_exploration')\n",
    "                self.remote_adresses = self.coupled_files[self.index]\n",
    "\n",
    "                self.can_local_address = await iget(self.remote_adresses['can'], cache)\n",
    "                if ignore_gps_file:\n",
    "                    self.gps_local_address = None\n",
    "                else:\n",
    "                    self.gps_local_address = await iget(self.remote_adresses['gps'], cache)\n",
    "\n",
    "                self.index += 1\n",
    "\n",
    "                return {\n",
    "                    'can': self.can_local_address,\n",
    "                    'gps': self.gps_local_address,\n",
    "                    'remote_addresses': self.remote_adresses\n",
    "                }\n",
    "            else:\n",
    "                raise Exception('max_index')\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f'Downloading next file failed on {e}')\n",
    "\n",
    "    def clear(self):\n",
    "        cache = init_cache('database_exploration')\n",
    "        print('Cache cleared')\n",
    "\n",
    "def coupled_files_file_namer(name, root):\n",
    "    return f'file_exploration&{name}&create_on={str(datetime.now()).replace(\" \", \"_\")}&root={root.replace(\"/\", \"_\")}.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON config parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-file analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def csv_file_namer(name, speed_t, prev_t, next_t):\n",
    "    return f'{name}&create_on={datetime.now()}&s={speed_t}&p={prev_t}&n={next_t}.csv'\n",
    "\n",
    "\n",
    "def analyse_events(canfile, gpsfile, prev_treshold, next_treshold, speed_treshold,\n",
    "                   verbose: bool = False, plot: bool = False, plot_name: str = ''):\n",
    "    ignore_gps_file = gpsfile is None\n",
    "    s, g, metadata = read_metadata(canfile, gpsfile, ignore_gps_file=ignore_gps_file)\n",
    "    speed, lead_dist, cc_state = read_data(s, g)\n",
    "    event_times, event_cc_states, event_speeds = find_crossing(speed, lead_dist, cc_state,\n",
    "                                                           prev_treshold=prev_treshold,\n",
    "                                                           next_treshold=next_treshold,\n",
    "                                                           speed_treshold=speed_treshold,\n",
    "                                                           verbose=verbose)\n",
    "    if plot:\n",
    "        strymread.plt_ts(lead_dist)\n",
    "        plot_events_over_lead(plot_name, lead_dist['Message'], lead_dist['Time'], event_times)\n",
    "    return event_times, event_cc_states, event_speeds, metadata\n",
    "\n",
    "\n",
    "async def explore_and_analyse_bdd(config_path):\n",
    "    \"\"\"\n",
    "    Launches the creation of the exploration and final analysis CSV (fake SQL databases)\n",
    "\n",
    "    :param config_path: path to a JSON giving the analysis' configuration\n",
    "    the format is as follows:\n",
    "    {\n",
    "        verbose: <bool>, set to True to have extensive logs\n",
    "        exploration:\n",
    "                    {\n",
    "                        remote_root: <str||None>, root of the fileshare exploration on CyVerse. Set to None\n",
    "                                    if you want to use the CSV file of a previous analysis\n",
    "                        db_exploration_name: <str||None>, small description of this exploration (an automated\n",
    "                                            logging of useful information as the date and the parameters is\n",
    "                                            already implemented). Set to None if you want to use the CSV file of a\n",
    "                                            previous analysis\n",
    "                        use_previous_exploration: <str||None>, if None, a new exploration is made using the\n",
    "                                                  parameters below. If a value is given, put the absolute location\n",
    "                                                  of the path for using a previous file exploration\n",
    "                    }\n",
    "        analysis:\n",
    "                    {\n",
    "                        db_analysis_name: <str>, small description of the full analysis. (automated\n",
    "                                        information are added)\n",
    "                        car_crossing_parameters:\n",
    "                            {\n",
    "                                enable: <bool>, set to True to look for this kind of events\n",
    "                                speed_threshold: <float>, minimum speed, in m/s\n",
    "                                previous_distance_threshold: <float>, minimum distance before the crossing\n",
    "                                next_distance_threshold: <float>, maximum distance after the crossing\n",
    "                                                        note: the crossing is detected as a discontinuity in\n",
    "                                                        lead_distance time series\n",
    "                            }\n",
    "                    }\n",
    "    }\n",
    "    note: the JSON object is intended to hold different analysis parameters, for different situations than car crossings\n",
    "    :return: finishes the whole exploration\n",
    "    \"\"\"\n",
    "    # Configuration reading\n",
    "    f = open(config_path)\n",
    "    config = json.load(f)\n",
    "\n",
    "    # Exploration of the file share\n",
    "    file_handler = FileHandler()\n",
    "    if 'use_previous_exploration' in config['exploration'].keys() and config['exploration']['use_previous_exploration']:\n",
    "        file_handler.explore(analyze=False,\n",
    "                             previous_exploration_path=config['exploration']['use_previous_exploration'],\n",
    "                             verbose=config['verbose'])\n",
    "    else:\n",
    "        file_handler.explore(analyze=True,\n",
    "                             root=config['exploration']['remote_root'],\n",
    "                             exploration_name=config['exploration']['db_exploration_name'],\n",
    "                             verbose=config['verbose'])\n",
    "\n",
    "    # Analysis of the events\n",
    "    full_analysis_csv_filename = csv_file_namer(config['analysis']['db_analysis_name'],\n",
    "                                                config['analysis']['car_crossing_parameters']['speed_threshold'],\n",
    "                                                config['analysis']['car_crossing_parameters']['previous_distance_threshold'],\n",
    "                                                config['analysis']['car_crossing_parameters']['next_distance_threshold'])\n",
    "\n",
    "    output_data = {'remote_addresses': [], 'event_time': [], 'event_speeds': [], 'event_cc_state': [], 'event_type': [], 'date_time': [], 'vin': []}\n",
    "    for index in range(file_handler.max_index):\n",
    "        print('\\nINDEX is ', index, ' out of ', file_handler.max_index)\n",
    "        try:\n",
    "            # download files\n",
    "            current_files = await file_handler.next(ignore_gps_file=True)\n",
    "            if config['verbose']:\n",
    "                print('starting analysis of the file: ', current_files['can'])\n",
    "            try:\n",
    "                # event analysis\n",
    "                event_times, event_cc_states, event_speeds, metadata = analyse_events(current_files['can'], current_files['gps'],\n",
    "                                                       prev_treshold=config['analysis']['car_crossing_parameters']['previous_distance_threshold'],\n",
    "                                                       next_treshold=config['analysis']['car_crossing_parameters']['next_distance_threshold'],\n",
    "                                                       speed_treshold=config['analysis']['car_crossing_parameters']['speed_threshold'],\n",
    "                                                       verbose=config['verbose'])\n",
    "                # add the metadata to the events\n",
    "                event_type = 'car_crossing'\n",
    "                number_of_events = len(event_times)\n",
    "                if number_of_events > 0:\n",
    "                    output_data['event_time'].extend(event_times)\n",
    "                    output_data['event_speeds'].extend(event_speeds)\n",
    "                    output_data['event_cc_state'].extend(event_cc_states)\n",
    "                    output_data['remote_addresses'].extend([current_files['remote_addresses']] * number_of_events)\n",
    "                    output_data['event_type'].extend([event_type] * number_of_events)\n",
    "                    output_data['date_time'].extend([metadata['date_time']] * number_of_events)\n",
    "                    output_data['vin'].extend([metadata['vin']] * number_of_events)\n",
    "\n",
    "            except Exception as err:\n",
    "                print(f'there was an issue trying to scan {current_files[\"can\"]}. \\nFailed on: {err}')\n",
    "        except Exception as err:\n",
    "            print(f'there was an issue trying to download file at index {index}. \\nFailed on: {err}')\n",
    "\n",
    "    # CSV logging\n",
    "    if config['verbose']:\n",
    "        print(f'starting to write the data to the CSV')\n",
    "    df = pd.DataFrame(data=output_data)\n",
    "    df.to_csv(path_or_buf=f'results/analysis&{full_analysis_csv_filename}')\n",
    "\n",
    "    file_handler.clear()\n",
    "\n",
    "    out_message = f'analysis finished, find it at: {full_analysis_csv_filename}'\n",
    "    if config['verbose']:\n",
    "        print(out_message)\n",
    "    return out_message\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# root_all = '/iplant/home/sprinkjm/publishable-circles'\n",
    "# root_small_vandertest = '/iplant/home/sprinkjm/publishable-circles/2T3W1RFVXKW033343/libpanda/2021_08_02'\n",
    "\n",
    "# full analysis test\n",
    "# config_path_test = 'example_config.json'\n",
    "# await explore_and_analyse_bdd(config_path_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config_path_full = 'full_analysis_config.json'\n",
    "await explore_and_analyse_bdd(config_path_full)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}